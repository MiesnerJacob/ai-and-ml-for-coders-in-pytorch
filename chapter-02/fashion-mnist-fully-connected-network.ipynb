{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2359a20",
   "metadata": {},
   "source": [
    "# Chapter 2 - Introduction to Computer Vision\n",
    "\n",
    "In this chapter we train a full connected neural network to classify Fashion MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc16ba8",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "immport torch.opim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4ee409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d20cd35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e5c1840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "class FashionMNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionMNISTModel, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = FashionMNISTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df92ee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Calculation\n",
    "\n",
    "def get_accuracy(pred, labels):\n",
    "    _, predictions = torch.max(pred, 1)\n",
    "    correct = (predictions == labels).float().sum()\n",
    "    accuracy = correct / labels.shape[0]\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0977404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        accuracy = get_accuracy(pred, y)\n",
    "        \n",
    "        # Accumulate totals\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += accuracy.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            current = batch * len(X)\n",
    "            avg_loss = total_loss / (batch + 1)\n",
    "            avg_accuracy = total_accuracy / (batch + 1) * 100\n",
    "            print(f\"Batch {batch}, Loss: {avg_loss:>7f}, Accuracy: {avg_accuracy:>0.2f}% [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    if avg_accuracy >= 95:\n",
    "        print(\"Reached 95% accuracy, stopping training.\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9c46924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Batch 0, Loss: 2.274945, Accuracy: 15.62% [    0/60000]\n",
      "Batch 100, Loss: 0.964410, Accuracy: 67.91% [ 6400/60000]\n",
      "Batch 200, Loss: 0.792410, Accuracy: 73.34% [12800/60000]\n",
      "Batch 300, Loss: 0.704631, Accuracy: 76.14% [19200/60000]\n",
      "Batch 400, Loss: 0.655057, Accuracy: 77.74% [25600/60000]\n",
      "Batch 500, Loss: 0.619781, Accuracy: 78.90% [32000/60000]\n",
      "Batch 600, Loss: 0.597841, Accuracy: 79.57% [38400/60000]\n",
      "Batch 700, Loss: 0.578714, Accuracy: 80.19% [44800/60000]\n",
      "Batch 800, Loss: 0.561106, Accuracy: 80.67% [51200/60000]\n",
      "Batch 900, Loss: 0.548462, Accuracy: 81.11% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.372117, Accuracy: 87.50% [    0/60000]\n",
      "Batch 100, Loss: 0.433634, Accuracy: 84.99% [ 6400/60000]\n",
      "Batch 200, Loss: 0.425313, Accuracy: 84.83% [12800/60000]\n",
      "Batch 300, Loss: 0.420409, Accuracy: 85.15% [19200/60000]\n",
      "Batch 400, Loss: 0.415066, Accuracy: 85.35% [25600/60000]\n",
      "Batch 500, Loss: 0.409897, Accuracy: 85.54% [32000/60000]\n",
      "Batch 600, Loss: 0.405248, Accuracy: 85.70% [38400/60000]\n",
      "Batch 700, Loss: 0.401007, Accuracy: 85.86% [44800/60000]\n",
      "Batch 800, Loss: 0.399716, Accuracy: 85.92% [51200/60000]\n",
      "Batch 900, Loss: 0.398881, Accuracy: 85.95% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.427253, Accuracy: 79.69% [    0/60000]\n",
      "Batch 100, Loss: 0.346510, Accuracy: 87.98% [ 6400/60000]\n",
      "Batch 200, Loss: 0.356620, Accuracy: 87.49% [12800/60000]\n",
      "Batch 300, Loss: 0.356594, Accuracy: 87.47% [19200/60000]\n",
      "Batch 400, Loss: 0.364455, Accuracy: 86.92% [25600/60000]\n",
      "Batch 500, Loss: 0.363959, Accuracy: 87.04% [32000/60000]\n",
      "Batch 600, Loss: 0.360487, Accuracy: 87.15% [38400/60000]\n",
      "Batch 700, Loss: 0.359339, Accuracy: 87.21% [44800/60000]\n",
      "Batch 800, Loss: 0.359222, Accuracy: 87.13% [51200/60000]\n",
      "Batch 900, Loss: 0.359356, Accuracy: 87.09% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.335593, Accuracy: 87.50% [    0/60000]\n",
      "Batch 100, Loss: 0.335014, Accuracy: 88.57% [ 6400/60000]\n",
      "Batch 200, Loss: 0.331147, Accuracy: 88.22% [12800/60000]\n",
      "Batch 300, Loss: 0.332179, Accuracy: 88.16% [19200/60000]\n",
      "Batch 400, Loss: 0.333436, Accuracy: 88.05% [25600/60000]\n",
      "Batch 500, Loss: 0.334063, Accuracy: 88.01% [32000/60000]\n",
      "Batch 600, Loss: 0.333486, Accuracy: 87.99% [38400/60000]\n",
      "Batch 700, Loss: 0.332950, Accuracy: 87.99% [44800/60000]\n",
      "Batch 800, Loss: 0.332506, Accuracy: 88.01% [51200/60000]\n",
      "Batch 900, Loss: 0.331002, Accuracy: 88.03% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.386983, Accuracy: 92.19% [    0/60000]\n",
      "Batch 100, Loss: 0.318340, Accuracy: 88.43% [ 6400/60000]\n",
      "Batch 200, Loss: 0.313054, Accuracy: 88.62% [12800/60000]\n",
      "Batch 300, Loss: 0.309564, Accuracy: 88.74% [19200/60000]\n",
      "Batch 400, Loss: 0.308711, Accuracy: 88.71% [25600/60000]\n",
      "Batch 500, Loss: 0.310511, Accuracy: 88.69% [32000/60000]\n",
      "Batch 600, Loss: 0.311480, Accuracy: 88.65% [38400/60000]\n",
      "Batch 700, Loss: 0.311250, Accuracy: 88.72% [44800/60000]\n",
      "Batch 800, Loss: 0.308974, Accuracy: 88.78% [51200/60000]\n",
      "Batch 900, Loss: 0.309460, Accuracy: 88.71% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.338859, Accuracy: 89.06% [    0/60000]\n",
      "Batch 100, Loss: 0.302533, Accuracy: 88.80% [ 6400/60000]\n",
      "Batch 200, Loss: 0.306588, Accuracy: 88.60% [12800/60000]\n",
      "Batch 300, Loss: 0.303234, Accuracy: 88.81% [19200/60000]\n",
      "Batch 400, Loss: 0.298467, Accuracy: 89.06% [25600/60000]\n",
      "Batch 500, Loss: 0.296371, Accuracy: 89.09% [32000/60000]\n",
      "Batch 600, Loss: 0.294997, Accuracy: 89.18% [38400/60000]\n",
      "Batch 700, Loss: 0.297063, Accuracy: 89.17% [44800/60000]\n",
      "Batch 800, Loss: 0.296783, Accuracy: 89.13% [51200/60000]\n",
      "Batch 900, Loss: 0.294406, Accuracy: 89.20% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.179613, Accuracy: 92.19% [    0/60000]\n",
      "Batch 100, Loss: 0.291871, Accuracy: 89.23% [ 6400/60000]\n",
      "Batch 200, Loss: 0.285939, Accuracy: 89.51% [12800/60000]\n",
      "Batch 300, Loss: 0.284261, Accuracy: 89.47% [19200/60000]\n",
      "Batch 400, Loss: 0.282428, Accuracy: 89.51% [25600/60000]\n",
      "Batch 500, Loss: 0.283924, Accuracy: 89.45% [32000/60000]\n",
      "Batch 600, Loss: 0.286016, Accuracy: 89.41% [38400/60000]\n",
      "Batch 700, Loss: 0.284564, Accuracy: 89.49% [44800/60000]\n",
      "Batch 800, Loss: 0.283083, Accuracy: 89.59% [51200/60000]\n",
      "Batch 900, Loss: 0.283437, Accuracy: 89.58% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.381006, Accuracy: 82.81% [    0/60000]\n",
      "Batch 100, Loss: 0.263875, Accuracy: 90.24% [ 6400/60000]\n",
      "Batch 200, Loss: 0.269379, Accuracy: 89.86% [12800/60000]\n",
      "Batch 300, Loss: 0.271354, Accuracy: 89.77% [19200/60000]\n",
      "Batch 400, Loss: 0.276058, Accuracy: 89.67% [25600/60000]\n",
      "Batch 500, Loss: 0.271112, Accuracy: 89.93% [32000/60000]\n",
      "Batch 600, Loss: 0.269488, Accuracy: 89.99% [38400/60000]\n",
      "Batch 700, Loss: 0.270221, Accuracy: 90.01% [44800/60000]\n",
      "Batch 800, Loss: 0.271698, Accuracy: 89.98% [51200/60000]\n",
      "Batch 900, Loss: 0.271364, Accuracy: 90.03% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.362665, Accuracy: 84.38% [    0/60000]\n",
      "Batch 100, Loss: 0.263068, Accuracy: 90.58% [ 6400/60000]\n",
      "Batch 200, Loss: 0.252580, Accuracy: 90.90% [12800/60000]\n",
      "Batch 300, Loss: 0.263784, Accuracy: 90.36% [19200/60000]\n",
      "Batch 400, Loss: 0.262224, Accuracy: 90.27% [25600/60000]\n",
      "Batch 500, Loss: 0.261556, Accuracy: 90.31% [32000/60000]\n",
      "Batch 600, Loss: 0.262608, Accuracy: 90.23% [38400/60000]\n",
      "Batch 700, Loss: 0.263261, Accuracy: 90.19% [44800/60000]\n",
      "Batch 800, Loss: 0.262435, Accuracy: 90.23% [51200/60000]\n",
      "Batch 900, Loss: 0.261833, Accuracy: 90.29% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.281647, Accuracy: 92.19% [    0/60000]\n",
      "Batch 100, Loss: 0.250702, Accuracy: 91.01% [ 6400/60000]\n",
      "Batch 200, Loss: 0.250263, Accuracy: 90.80% [12800/60000]\n",
      "Batch 300, Loss: 0.250218, Accuracy: 90.76% [19200/60000]\n",
      "Batch 400, Loss: 0.250722, Accuracy: 90.68% [25600/60000]\n",
      "Batch 500, Loss: 0.250314, Accuracy: 90.73% [32000/60000]\n",
      "Batch 600, Loss: 0.249594, Accuracy: 90.73% [38400/60000]\n",
      "Batch 700, Loss: 0.250938, Accuracy: 90.66% [44800/60000]\n",
      "Batch 800, Loss: 0.250822, Accuracy: 90.71% [51200/60000]\n",
      "Batch 900, Loss: 0.250994, Accuracy: 90.73% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.143734, Accuracy: 96.88% [    0/60000]\n",
      "Batch 100, Loss: 0.248491, Accuracy: 90.75% [ 6400/60000]\n",
      "Batch 200, Loss: 0.243323, Accuracy: 90.80% [12800/60000]\n",
      "Batch 300, Loss: 0.244066, Accuracy: 90.92% [19200/60000]\n",
      "Batch 400, Loss: 0.241314, Accuracy: 91.11% [25600/60000]\n",
      "Batch 500, Loss: 0.240792, Accuracy: 91.10% [32000/60000]\n",
      "Batch 600, Loss: 0.244235, Accuracy: 91.05% [38400/60000]\n",
      "Batch 700, Loss: 0.245612, Accuracy: 90.95% [44800/60000]\n",
      "Batch 800, Loss: 0.245963, Accuracy: 90.94% [51200/60000]\n",
      "Batch 900, Loss: 0.243704, Accuracy: 90.97% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.149823, Accuracy: 93.75% [    0/60000]\n",
      "Batch 100, Loss: 0.232909, Accuracy: 91.26% [ 6400/60000]\n",
      "Batch 200, Loss: 0.231228, Accuracy: 91.30% [12800/60000]\n",
      "Batch 300, Loss: 0.233802, Accuracy: 91.11% [19200/60000]\n",
      "Batch 400, Loss: 0.236476, Accuracy: 91.07% [25600/60000]\n",
      "Batch 500, Loss: 0.236690, Accuracy: 91.09% [32000/60000]\n",
      "Batch 600, Loss: 0.235015, Accuracy: 91.15% [38400/60000]\n",
      "Batch 700, Loss: 0.236602, Accuracy: 91.15% [44800/60000]\n",
      "Batch 800, Loss: 0.237758, Accuracy: 91.13% [51200/60000]\n",
      "Batch 900, Loss: 0.237425, Accuracy: 91.11% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.365042, Accuracy: 85.94% [    0/60000]\n",
      "Batch 100, Loss: 0.230583, Accuracy: 91.38% [ 6400/60000]\n",
      "Batch 200, Loss: 0.224573, Accuracy: 91.71% [12800/60000]\n",
      "Batch 300, Loss: 0.224061, Accuracy: 91.79% [19200/60000]\n",
      "Batch 400, Loss: 0.228308, Accuracy: 91.63% [25600/60000]\n",
      "Batch 500, Loss: 0.224970, Accuracy: 91.75% [32000/60000]\n",
      "Batch 600, Loss: 0.224876, Accuracy: 91.71% [38400/60000]\n",
      "Batch 700, Loss: 0.224068, Accuracy: 91.66% [44800/60000]\n",
      "Batch 800, Loss: 0.226096, Accuracy: 91.57% [51200/60000]\n",
      "Batch 900, Loss: 0.228138, Accuracy: 91.50% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.187634, Accuracy: 92.19% [    0/60000]\n",
      "Batch 100, Loss: 0.226445, Accuracy: 91.40% [ 6400/60000]\n",
      "Batch 200, Loss: 0.227024, Accuracy: 91.37% [12800/60000]\n",
      "Batch 300, Loss: 0.219334, Accuracy: 91.72% [19200/60000]\n",
      "Batch 400, Loss: 0.220498, Accuracy: 91.63% [25600/60000]\n",
      "Batch 500, Loss: 0.223503, Accuracy: 91.56% [32000/60000]\n",
      "Batch 600, Loss: 0.223956, Accuracy: 91.54% [38400/60000]\n",
      "Batch 700, Loss: 0.223239, Accuracy: 91.63% [44800/60000]\n",
      "Batch 800, Loss: 0.222164, Accuracy: 91.68% [51200/60000]\n",
      "Batch 900, Loss: 0.224522, Accuracy: 91.59% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.330099, Accuracy: 84.38% [    0/60000]\n",
      "Batch 100, Loss: 0.198227, Accuracy: 92.39% [ 6400/60000]\n",
      "Batch 200, Loss: 0.205975, Accuracy: 92.25% [12800/60000]\n",
      "Batch 300, Loss: 0.209059, Accuracy: 92.23% [19200/60000]\n",
      "Batch 400, Loss: 0.214290, Accuracy: 92.20% [25600/60000]\n",
      "Batch 500, Loss: 0.216822, Accuracy: 92.06% [32000/60000]\n",
      "Batch 600, Loss: 0.216092, Accuracy: 92.06% [38400/60000]\n",
      "Batch 700, Loss: 0.216590, Accuracy: 91.98% [44800/60000]\n",
      "Batch 800, Loss: 0.216261, Accuracy: 91.96% [51200/60000]\n",
      "Batch 900, Loss: 0.217417, Accuracy: 91.87% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.229139, Accuracy: 92.19% [    0/60000]\n",
      "Batch 100, Loss: 0.218273, Accuracy: 91.83% [ 6400/60000]\n",
      "Batch 200, Loss: 0.214178, Accuracy: 91.85% [12800/60000]\n",
      "Batch 300, Loss: 0.209787, Accuracy: 92.14% [19200/60000]\n",
      "Batch 400, Loss: 0.210876, Accuracy: 92.16% [25600/60000]\n",
      "Batch 500, Loss: 0.210764, Accuracy: 92.10% [32000/60000]\n",
      "Batch 600, Loss: 0.212028, Accuracy: 92.01% [38400/60000]\n",
      "Batch 700, Loss: 0.212381, Accuracy: 92.00% [44800/60000]\n",
      "Batch 800, Loss: 0.211015, Accuracy: 92.01% [51200/60000]\n",
      "Batch 900, Loss: 0.211173, Accuracy: 92.01% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.154462, Accuracy: 95.31% [    0/60000]\n",
      "Batch 100, Loss: 0.196562, Accuracy: 92.81% [ 6400/60000]\n",
      "Batch 200, Loss: 0.200014, Accuracy: 92.72% [12800/60000]\n",
      "Batch 300, Loss: 0.204846, Accuracy: 92.37% [19200/60000]\n",
      "Batch 400, Loss: 0.202505, Accuracy: 92.40% [25600/60000]\n",
      "Batch 500, Loss: 0.202615, Accuracy: 92.43% [32000/60000]\n",
      "Batch 600, Loss: 0.202710, Accuracy: 92.41% [38400/60000]\n",
      "Batch 700, Loss: 0.202624, Accuracy: 92.44% [44800/60000]\n",
      "Batch 800, Loss: 0.205758, Accuracy: 92.32% [51200/60000]\n",
      "Batch 900, Loss: 0.206705, Accuracy: 92.27% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.270590, Accuracy: 87.50% [    0/60000]\n",
      "Batch 100, Loss: 0.182811, Accuracy: 93.38% [ 6400/60000]\n",
      "Batch 200, Loss: 0.185561, Accuracy: 93.05% [12800/60000]\n",
      "Batch 300, Loss: 0.191957, Accuracy: 92.77% [19200/60000]\n",
      "Batch 400, Loss: 0.195402, Accuracy: 92.62% [25600/60000]\n",
      "Batch 500, Loss: 0.193434, Accuracy: 92.79% [32000/60000]\n",
      "Batch 600, Loss: 0.197356, Accuracy: 92.60% [38400/60000]\n",
      "Batch 700, Loss: 0.197284, Accuracy: 92.64% [44800/60000]\n",
      "Batch 800, Loss: 0.197866, Accuracy: 92.64% [51200/60000]\n",
      "Batch 900, Loss: 0.199080, Accuracy: 92.61% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.197565, Accuracy: 95.31% [    0/60000]\n",
      "Batch 100, Loss: 0.185868, Accuracy: 93.60% [ 6400/60000]\n",
      "Batch 200, Loss: 0.185635, Accuracy: 93.38% [12800/60000]\n",
      "Batch 300, Loss: 0.187363, Accuracy: 93.32% [19200/60000]\n",
      "Batch 400, Loss: 0.189912, Accuracy: 93.19% [25600/60000]\n",
      "Batch 500, Loss: 0.190638, Accuracy: 93.09% [32000/60000]\n",
      "Batch 600, Loss: 0.192315, Accuracy: 93.03% [38400/60000]\n",
      "Batch 700, Loss: 0.191942, Accuracy: 93.07% [44800/60000]\n",
      "Batch 800, Loss: 0.191197, Accuracy: 93.08% [51200/60000]\n",
      "Batch 900, Loss: 0.192982, Accuracy: 92.97% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.229844, Accuracy: 93.75% [    0/60000]\n",
      "Batch 100, Loss: 0.188667, Accuracy: 93.12% [ 6400/60000]\n",
      "Batch 200, Loss: 0.188637, Accuracy: 93.17% [12800/60000]\n",
      "Batch 300, Loss: 0.188787, Accuracy: 93.08% [19200/60000]\n",
      "Batch 400, Loss: 0.185775, Accuracy: 93.15% [25600/60000]\n",
      "Batch 500, Loss: 0.186549, Accuracy: 93.14% [32000/60000]\n",
      "Batch 600, Loss: 0.187727, Accuracy: 93.18% [38400/60000]\n",
      "Batch 700, Loss: 0.187143, Accuracy: 93.18% [44800/60000]\n",
      "Batch 800, Loss: 0.187327, Accuracy: 93.16% [51200/60000]\n",
      "Batch 900, Loss: 0.189848, Accuracy: 93.04% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.210514, Accuracy: 92.19% [    0/60000]\n",
      "Batch 100, Loss: 0.183144, Accuracy: 92.91% [ 6400/60000]\n",
      "Batch 200, Loss: 0.177629, Accuracy: 93.03% [12800/60000]\n",
      "Batch 300, Loss: 0.182196, Accuracy: 93.06% [19200/60000]\n",
      "Batch 400, Loss: 0.183393, Accuracy: 93.08% [25600/60000]\n",
      "Batch 500, Loss: 0.182544, Accuracy: 93.18% [32000/60000]\n",
      "Batch 600, Loss: 0.184781, Accuracy: 93.09% [38400/60000]\n",
      "Batch 700, Loss: 0.184892, Accuracy: 93.07% [44800/60000]\n",
      "Batch 800, Loss: 0.185264, Accuracy: 93.08% [51200/60000]\n",
      "Batch 900, Loss: 0.185234, Accuracy: 93.06% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.086543, Accuracy: 98.44% [    0/60000]\n",
      "Batch 100, Loss: 0.167639, Accuracy: 93.64% [ 6400/60000]\n",
      "Batch 200, Loss: 0.172396, Accuracy: 93.42% [12800/60000]\n",
      "Batch 300, Loss: 0.175529, Accuracy: 93.38% [19200/60000]\n",
      "Batch 400, Loss: 0.175224, Accuracy: 93.38% [25600/60000]\n",
      "Batch 500, Loss: 0.175854, Accuracy: 93.37% [32000/60000]\n",
      "Batch 600, Loss: 0.179430, Accuracy: 93.20% [38400/60000]\n",
      "Batch 700, Loss: 0.179122, Accuracy: 93.23% [44800/60000]\n",
      "Batch 800, Loss: 0.179584, Accuracy: 93.23% [51200/60000]\n",
      "Batch 900, Loss: 0.179151, Accuracy: 93.28% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.156154, Accuracy: 92.19% [    0/60000]\n",
      "Batch 100, Loss: 0.169502, Accuracy: 93.80% [ 6400/60000]\n",
      "Batch 200, Loss: 0.170367, Accuracy: 93.89% [12800/60000]\n",
      "Batch 300, Loss: 0.175332, Accuracy: 93.58% [19200/60000]\n",
      "Batch 400, Loss: 0.174704, Accuracy: 93.54% [25600/60000]\n",
      "Batch 500, Loss: 0.175289, Accuracy: 93.54% [32000/60000]\n",
      "Batch 600, Loss: 0.175387, Accuracy: 93.48% [38400/60000]\n",
      "Batch 700, Loss: 0.175015, Accuracy: 93.50% [44800/60000]\n",
      "Batch 800, Loss: 0.175307, Accuracy: 93.49% [51200/60000]\n",
      "Batch 900, Loss: 0.175857, Accuracy: 93.44% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.143357, Accuracy: 96.88% [    0/60000]\n",
      "Batch 100, Loss: 0.156618, Accuracy: 94.14% [ 6400/60000]\n",
      "Batch 200, Loss: 0.156332, Accuracy: 94.28% [12800/60000]\n",
      "Batch 300, Loss: 0.156010, Accuracy: 94.29% [19200/60000]\n",
      "Batch 400, Loss: 0.162287, Accuracy: 94.08% [25600/60000]\n",
      "Batch 500, Loss: 0.163985, Accuracy: 94.01% [32000/60000]\n",
      "Batch 600, Loss: 0.167226, Accuracy: 93.82% [38400/60000]\n",
      "Batch 700, Loss: 0.169234, Accuracy: 93.75% [44800/60000]\n",
      "Batch 800, Loss: 0.171412, Accuracy: 93.68% [51200/60000]\n",
      "Batch 900, Loss: 0.172261, Accuracy: 93.60% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.187288, Accuracy: 92.19% [    0/60000]\n",
      "Batch 100, Loss: 0.164357, Accuracy: 93.72% [ 6400/60000]\n",
      "Batch 200, Loss: 0.163510, Accuracy: 93.73% [12800/60000]\n",
      "Batch 300, Loss: 0.160391, Accuracy: 93.89% [19200/60000]\n",
      "Batch 400, Loss: 0.160706, Accuracy: 93.91% [25600/60000]\n",
      "Batch 500, Loss: 0.161177, Accuracy: 93.87% [32000/60000]\n",
      "Batch 600, Loss: 0.164757, Accuracy: 93.74% [38400/60000]\n",
      "Batch 700, Loss: 0.165688, Accuracy: 93.73% [44800/60000]\n",
      "Batch 800, Loss: 0.166407, Accuracy: 93.72% [51200/60000]\n",
      "Batch 900, Loss: 0.168044, Accuracy: 93.67% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.147534, Accuracy: 93.75% [    0/60000]\n",
      "Batch 100, Loss: 0.162434, Accuracy: 93.61% [ 6400/60000]\n",
      "Batch 200, Loss: 0.162548, Accuracy: 93.80% [12800/60000]\n",
      "Batch 300, Loss: 0.162140, Accuracy: 93.86% [19200/60000]\n",
      "Batch 400, Loss: 0.161170, Accuracy: 93.99% [25600/60000]\n",
      "Batch 500, Loss: 0.164394, Accuracy: 93.84% [32000/60000]\n",
      "Batch 600, Loss: 0.165027, Accuracy: 93.82% [38400/60000]\n",
      "Batch 700, Loss: 0.164512, Accuracy: 93.82% [44800/60000]\n",
      "Batch 800, Loss: 0.166044, Accuracy: 93.77% [51200/60000]\n",
      "Batch 900, Loss: 0.165626, Accuracy: 93.83% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.104878, Accuracy: 96.88% [    0/60000]\n",
      "Batch 100, Loss: 0.158718, Accuracy: 93.98% [ 6400/60000]\n",
      "Batch 200, Loss: 0.155855, Accuracy: 94.05% [12800/60000]\n",
      "Batch 300, Loss: 0.157115, Accuracy: 94.10% [19200/60000]\n",
      "Batch 400, Loss: 0.160150, Accuracy: 93.98% [25600/60000]\n",
      "Batch 500, Loss: 0.159210, Accuracy: 94.03% [32000/60000]\n",
      "Batch 600, Loss: 0.161764, Accuracy: 93.93% [38400/60000]\n",
      "Batch 700, Loss: 0.161883, Accuracy: 93.91% [44800/60000]\n",
      "Batch 800, Loss: 0.161854, Accuracy: 93.88% [51200/60000]\n",
      "Batch 900, Loss: 0.162501, Accuracy: 93.87% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.149572, Accuracy: 96.88% [    0/60000]\n",
      "Batch 100, Loss: 0.152434, Accuracy: 94.34% [ 6400/60000]\n",
      "Batch 200, Loss: 0.146589, Accuracy: 94.61% [12800/60000]\n",
      "Batch 300, Loss: 0.151658, Accuracy: 94.50% [19200/60000]\n",
      "Batch 400, Loss: 0.148607, Accuracy: 94.60% [25600/60000]\n",
      "Batch 500, Loss: 0.150373, Accuracy: 94.51% [32000/60000]\n",
      "Batch 600, Loss: 0.152161, Accuracy: 94.42% [38400/60000]\n",
      "Batch 700, Loss: 0.154697, Accuracy: 94.33% [44800/60000]\n",
      "Batch 800, Loss: 0.155599, Accuracy: 94.27% [51200/60000]\n",
      "Batch 900, Loss: 0.156099, Accuracy: 94.23% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.184749, Accuracy: 92.19% [    0/60000]\n",
      "Batch 100, Loss: 0.163190, Accuracy: 93.86% [ 6400/60000]\n",
      "Batch 200, Loss: 0.157287, Accuracy: 94.05% [12800/60000]\n",
      "Batch 300, Loss: 0.157786, Accuracy: 94.05% [19200/60000]\n",
      "Batch 400, Loss: 0.155351, Accuracy: 94.28% [25600/60000]\n",
      "Batch 500, Loss: 0.155737, Accuracy: 94.22% [32000/60000]\n",
      "Batch 600, Loss: 0.153841, Accuracy: 94.30% [38400/60000]\n",
      "Batch 700, Loss: 0.154092, Accuracy: 94.27% [44800/60000]\n",
      "Batch 800, Loss: 0.153476, Accuracy: 94.24% [51200/60000]\n",
      "Batch 900, Loss: 0.154924, Accuracy: 94.21% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.216919, Accuracy: 90.62% [    0/60000]\n",
      "Batch 100, Loss: 0.139601, Accuracy: 94.65% [ 6400/60000]\n",
      "Batch 200, Loss: 0.145117, Accuracy: 94.43% [12800/60000]\n",
      "Batch 300, Loss: 0.148247, Accuracy: 94.43% [19200/60000]\n",
      "Batch 400, Loss: 0.143506, Accuracy: 94.61% [25600/60000]\n",
      "Batch 500, Loss: 0.144573, Accuracy: 94.61% [32000/60000]\n",
      "Batch 600, Loss: 0.146327, Accuracy: 94.52% [38400/60000]\n",
      "Batch 700, Loss: 0.149118, Accuracy: 94.41% [44800/60000]\n",
      "Batch 800, Loss: 0.149898, Accuracy: 94.37% [51200/60000]\n",
      "Batch 900, Loss: 0.151171, Accuracy: 94.31% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.148169, Accuracy: 93.75% [    0/60000]\n",
      "Batch 100, Loss: 0.145825, Accuracy: 94.83% [ 6400/60000]\n",
      "Batch 200, Loss: 0.144543, Accuracy: 94.68% [12800/60000]\n",
      "Batch 300, Loss: 0.145230, Accuracy: 94.62% [19200/60000]\n",
      "Batch 400, Loss: 0.146151, Accuracy: 94.56% [25600/60000]\n",
      "Batch 500, Loss: 0.147475, Accuracy: 94.49% [32000/60000]\n",
      "Batch 600, Loss: 0.147711, Accuracy: 94.51% [38400/60000]\n",
      "Batch 700, Loss: 0.147245, Accuracy: 94.53% [44800/60000]\n",
      "Batch 800, Loss: 0.147405, Accuracy: 94.50% [51200/60000]\n",
      "Batch 900, Loss: 0.148613, Accuracy: 94.43% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.148709, Accuracy: 95.31% [    0/60000]\n",
      "Batch 100, Loss: 0.153365, Accuracy: 94.01% [ 6400/60000]\n",
      "Batch 200, Loss: 0.145434, Accuracy: 94.39% [12800/60000]\n",
      "Batch 300, Loss: 0.143858, Accuracy: 94.52% [19200/60000]\n",
      "Batch 400, Loss: 0.144366, Accuracy: 94.53% [25600/60000]\n",
      "Batch 500, Loss: 0.142122, Accuracy: 94.63% [32000/60000]\n",
      "Batch 600, Loss: 0.142746, Accuracy: 94.61% [38400/60000]\n",
      "Batch 700, Loss: 0.143034, Accuracy: 94.63% [44800/60000]\n",
      "Batch 800, Loss: 0.144661, Accuracy: 94.54% [51200/60000]\n",
      "Batch 900, Loss: 0.145190, Accuracy: 94.52% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.221992, Accuracy: 90.62% [    0/60000]\n",
      "Batch 100, Loss: 0.128562, Accuracy: 95.28% [ 6400/60000]\n",
      "Batch 200, Loss: 0.134532, Accuracy: 94.85% [12800/60000]\n",
      "Batch 300, Loss: 0.134515, Accuracy: 94.87% [19200/60000]\n",
      "Batch 400, Loss: 0.135401, Accuracy: 94.86% [25600/60000]\n",
      "Batch 500, Loss: 0.138004, Accuracy: 94.83% [32000/60000]\n",
      "Batch 600, Loss: 0.137430, Accuracy: 94.90% [38400/60000]\n",
      "Batch 700, Loss: 0.137962, Accuracy: 94.89% [44800/60000]\n",
      "Batch 800, Loss: 0.139199, Accuracy: 94.87% [51200/60000]\n",
      "Batch 900, Loss: 0.139906, Accuracy: 94.83% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.072224, Accuracy: 98.44% [    0/60000]\n",
      "Batch 100, Loss: 0.139634, Accuracy: 95.08% [ 6400/60000]\n",
      "Batch 200, Loss: 0.140196, Accuracy: 95.01% [12800/60000]\n",
      "Batch 300, Loss: 0.138657, Accuracy: 95.04% [19200/60000]\n",
      "Batch 400, Loss: 0.138086, Accuracy: 95.04% [25600/60000]\n",
      "Batch 500, Loss: 0.135993, Accuracy: 95.03% [32000/60000]\n",
      "Batch 600, Loss: 0.136524, Accuracy: 94.96% [38400/60000]\n",
      "Batch 700, Loss: 0.137618, Accuracy: 94.92% [44800/60000]\n",
      "Batch 800, Loss: 0.138197, Accuracy: 94.86% [51200/60000]\n",
      "Batch 900, Loss: 0.137685, Accuracy: 94.84% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.121981, Accuracy: 96.88% [    0/60000]\n",
      "Batch 100, Loss: 0.140762, Accuracy: 94.97% [ 6400/60000]\n",
      "Batch 200, Loss: 0.140568, Accuracy: 94.75% [12800/60000]\n",
      "Batch 300, Loss: 0.134195, Accuracy: 94.99% [19200/60000]\n",
      "Batch 400, Loss: 0.134980, Accuracy: 94.99% [25600/60000]\n",
      "Batch 500, Loss: 0.135254, Accuracy: 94.94% [32000/60000]\n",
      "Batch 600, Loss: 0.133622, Accuracy: 94.99% [38400/60000]\n",
      "Batch 700, Loss: 0.134548, Accuracy: 94.96% [44800/60000]\n",
      "Batch 800, Loss: 0.134626, Accuracy: 94.95% [51200/60000]\n",
      "Batch 900, Loss: 0.134249, Accuracy: 94.99% [57600/60000]\n",
      "\n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.225112, Accuracy: 90.62% [    0/60000]\n",
      "Batch 100, Loss: 0.118339, Accuracy: 95.76% [ 6400/60000]\n",
      "Batch 200, Loss: 0.124785, Accuracy: 95.59% [12800/60000]\n",
      "Batch 300, Loss: 0.127263, Accuracy: 95.44% [19200/60000]\n",
      "Batch 400, Loss: 0.127151, Accuracy: 95.39% [25600/60000]\n",
      "Batch 500, Loss: 0.129601, Accuracy: 95.26% [32000/60000]\n",
      "Batch 600, Loss: 0.129701, Accuracy: 95.28% [38400/60000]\n",
      "Batch 700, Loss: 0.132437, Accuracy: 95.15% [44800/60000]\n",
      "Batch 800, Loss: 0.132961, Accuracy: 95.10% [51200/60000]\n",
      "Batch 900, Loss: 0.134065, Accuracy: 95.04% [57600/60000]\n",
      "Reached 95% accuracy, stopping training.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    should_stop = train(train_loader, model, loss_function, optimizer)\n",
    "    if should_stop:\n",
    "        break\n",
    "    print(\"\\n\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "285ab60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the model\n",
    "\n",
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_function(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29ccef44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.396822 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Eval\n",
    "test(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a77593b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict single image function\n",
    "\n",
    "def predict_single_image(image, label, model):\n",
    "    model.eval()\n",
    "\n",
    "    image = image.unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(image)\n",
    "        print(prediction)\n",
    "        prediction_label = prediction.argmax(1).item()\n",
    "\n",
    "    plt.imshow(image.squeeze(), cmap=\"gray\")\n",
    "    plt.title(f\"Predicted: {prediction_label}, Actual: {label}\")\n",
    "    plt.show()\n",
    "\n",
    "    return prediction_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "385d54ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.4826e+01, -3.0134e+01, -2.1924e+01, -2.3928e+01, -1.9757e+01,\n",
      "         -1.4697e+01, -2.5125e+01, -9.6034e+00, -2.2588e+01, -6.7828e-05]])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAla0lEQVR4nO3dC3QU5f3/8W/AEK5JTLgk4RrulpuKgBFFFCSipSL0VNTTgoeCIKCAiGKVi1rjrYoXivbUEq2ISiugnEoL4eYFtICUQyuUUJAgBOSWADEJkPmf7+N/88vmQpgh2Wez+36dMyw7O8/u7OxkPvs88+wzEY7jOAIAQIDVCvQLAgCgCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAElTZt2sioUaOK769du1YiIiLMbbCuIy5O//79zYTwQwChWHp6ujnY+6a6detKx44dZeLEiXLo0CGpSf72t7/J7NmzJRhlZmbKz3/+c7n00kulfv36cu2118qaNWuq5Lm/+eab4s/uxIkTnp/n6aeflqVLl0pNoPvmPffcI02bNpV69erJlVdeKYsXL7a9WrgABBDKeOKJJ+TPf/6zvPbaa3LNNdfI/PnzJSUlRfLy8gK+Lv369ZMffvjB3LoNoDlz5kiwycrKMtvys88+k4ceekjS0tLk1KlTMmjQIFm/fv1FP/8777wjCQkJ5v9/+ctfQj6AcnNzTYD/9a9/lXvvvVdeeOEFadSokfziF7+Qd9991/bqoRKXVLYAws/gwYPlqquuMv//9a9/LfHx8fLiiy/KsmXL5M477yy3zOnTp6VBgwZVvi61atUy3+ZDxTPPPGNqJtu3b5dOnTqZeWPGjJHOnTvLlClTZPPmzZ6fW8cV1oPuXXfdJXv27JGFCxeazy+UvfHGG6ZGmZGRITfeeKOZN378eLn66qvlwQcfNDXNOnXq2F5NVIAaECrl+8PWg5rS8x8NGzaU3bt3yy233GK+cd59993msaKiIpk7d6506dLFBEezZs3MN9Pjx4+XOVg+9dRT0qJFC9MMdcMNN8i///3vMq9d0TmgL7/80ry2NmNp8HXv3l1efvnl4vWbN2+e+X/JJkWfql5HpdtCp8p8+umncsUVVxSHj9Ln/tnPfiZbtmyRXbt2iVeff/657N27V0aMGGEmrVHt37+/zHL6/nVbdevWzbz/Jk2ayM033yybNm0yj+u20i8Ub731VvG2853z0ls9B1aaNneW3MZqwYIFZt/RprGoqCj5yU9+YmrTF2Lfvn2yY8eOC9qeuv6+fdT3pUVrQNnZ2bJu3boLej3YQQ0IlfIdWLUm5HP27FlJTU01zR/a7KEHUaUHcj2XpG3y999/vwktbcr7+uuvzQEyMjLSLDdz5kxzcNcQ0UkPvtoMVVhYWOn6rFy5Un76059KYmKiPPDAA6bJSc99LF++3NzXdThw4IBZTpsSS6uOdRwwYIC51QA4n4KCAhOapfm2n9aAOnToIF5ojaddu3bSq1cv6dq1q3nORYsWmaa+kkaPHm3ev9Z0tYakn6UeyDdu3GhqvrrNdH7v3r1l7Nixpow+r1saNhryGq6XXHKJfPzxx3LfffeZAJwwYcJ5y/7qV78y4VHZ1WJ0e+p5n/Ntz5tuusn1uiNA9HpAgFqwYIH+tTurVq1yvv/+eycrK8t57733nPj4eKdevXrO/v37zXIjR440yz3yyCN+5T/99FMzf+HChX7zV6xY4Tf/8OHDTp06dZxbb73VKSoqKl7u0UcfNcvp8/usWbPGzNNbdfbsWSc5Odlp3bq1c/z4cb/XKflcEyZMMOVKq451VLo+OlVmyJAhTmxsrJObm+s3PyUlxTzvCy+84HhRWFhoPqff/OY3xfPuuusup0ePHn7LrV692rzO/fffX+Y5Sr7PBg0alHmPSueV9z5nzZpVZnvn5eWVWS41NdVp27at37zrr7/eTKXnXcjhadKkSU6tWrWcvXv3+s0fMWKEKT9x4sRKnwP20ASHMgYOHGiaNVq2bGmacrS5bcmSJdK8eXO/5bStvSTteRQTE2O+cR45cqR46tmzp3kOX0+vVatWmVrEpEmT/JptJk+eXOm6aS1Fayy6bGxsrN9jpZuAylNd66g1n8pqP75tpueA7rjjDvNe/vvf/5rn9DV/aYcLLz755BM5evSo3zk6/f+//vUvv2ZDPVmv72fWrFllnuNCtp8bJWsmOTk5Zjtff/318r///c/cPx9tcr2Qa2VqTa127dqmye2LL74wtXXt2KH768VsTwQGTXAoQ8+faPdrbTbR8yN6vkLb1UvSx/TcSEl6/kIPLNrmX57Dhw+b22+//dbclm5q0tArr3mqvOZAbWLyIhDreD7a7PXqq6/KI488YroLq/bt28tvf/tbmT59uglBr73fkpOTzbkWPSnvazbTpihtmtNebb7tl5SUJHFxcVLdtDlTg27Dhg1lelDqZ6BfBC6WnvvTjhfjxo2Tvn37mnnaJKvn+DTsvW5PBAYBhDK07d/XC64ieqArHUratq8Hdj3glUcP3rYFwzrq76r0/NO2bdtMD63LL79c3nzzTfOYBr+Xrsh6fiU/P7/c80d6gNaAq4oaTkXPce7cOb/7GnR6Xkx792kPSq1N63vV7vEvvfSS+RyqivZ00/NMWtvT9dBg93Va8bI9ETgEEKqMfuPWpiv9JlreiWGf1q1bF9dG2rZtWzz/+++/L9MTrbzXUNqNWZsK3R4oA7GOF0J77unvgXx0nXR9fN/i3fjwww9N+OhJ/8aNG/s9tnPnTnnsscdMbUQ7jOj7//vf/y7Hjh07by2oou2ntb/yfuDqqzH6aCBqB4GPPvpIWrVqVTy/qn5wW5qGm3a+KLk91fn2EdjHOSBUGW2H12+gTz75ZJnHtKeV78ClBwXtaaZNUSXb+bXZpDL67VabmnTZ0gfCks/l+01S6WWqax0vtBt2efTchYaI9k7z0iylzW8aktoMpbWBktO0adNMM5Svxjd8+HDzfsr7kW7p7Vde0GiAafOZ1t58Dh48WHzOxUfPy5R+Ti2nXbOrsht2efRLw+uvv256SlIDCnIWO0AgSHvB/fOf/zzvctoTSntJlefee+81zzF48GDnpZdecl577TXngQcecJKSkpzFixcXLzdjxgyz3C233GKWGT16tFmmcePG5+0F5+uxFhkZaXpjzZ4923njjTecKVOmOIMGDSpe5oMPPjDlfvnLXzrvvPOOs2jRompbRze94LS3Vu/evZ2nnnrK+eMf/2jWW3sYXnHFFWV6xvk+D72tyHfffWd6gU2ePLnCZYYPH256yGlPOaXbxPf+X375ZbMNhg0b5rz66qvFZfQ962f8u9/9zmy7jRs3mvlHjhwx87Un29y5c52nn37aadmypXPllVf69VrbsWOH6UXYrVs3s+2eeeYZp127dqZXni63Z8+eKukFpy677DJn5syZZntqL8C4uDjzWfh6bSJ4EUCo0gBSf/jDH5yePXuaA2ujRo3MQWj69OnOgQMHipc5d+6cM2fOHCcxMdEs179/f2f79u3mwFFZAKnPPvvMuemmm8zz67p0797d7wCq3bW1i26TJk2ciIiIMgezqlxHNwF07Ngx57bbbnMSEhLMAVq7lD/88MNlwkfp+9H11sCtiAaELpORkVHhMunp6WaZZcuWFW+b559/3uncubNZB91GGkabN2/2C5B+/fqZ91262/k//vEPp2vXrqZsp06dTMCX1w37o48+Mp9L3bp1nTZt2jjPPvus86c//anKA0i7XGsI6vroF4Rx48Y5hw4duqCysCtC/7FdCwNQljYXatfur776yvaqANWCTghAENLvhdqTS8/vAKGKGhAAwAp6wQEArCCAAABWEEAAACsIIACAFUHXC07HiNJruehFzqp6dF4AQPXTvm0nT540A9+WHjMyqANIw0cHLgQA1GxZWVllRs0P6iY4rfkAAGq+yo7ntarzmjJ67Xi95nyfPn0u+NfcNLsBQGio7HheLQH0/vvvy9SpU83FqLZs2SI9evSQ1NTU4ot9AQBQLYOR6mi/EyZM8BvUUQcJTEtLq7RsTk6OGYSQiYmJiUlq9KTH8/Op8hpQYWGhbN682e9CUNoLQu/rpXlL04tW6RUdS04AgNBX5QF05MgRc8GvZs2a+c3X+9nZ2WWWT0tLMxfh8k30gAOA8GC9F9yMGTPMlRJ9k3bbAwCEvir/HZBek14vx3vo0CG/+Xo/ISGhzPJRUVFmAgCElyqvAdWpU0d69uwpGRkZfqMb6P2UlJSqfjkAQA1VLSMhaBfskSNHylVXXSW9e/eWuXPnyunTp+Wee+6pjpcDANRA1RJAd9xxh3z//fcyc+ZM0/Hg8ssvlxUrVpTpmAAACF9Bd0VU7YatveEAADWbdiyLjo4O3l5wAIDwRAABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIABAaATR79myJiIjwmzp37lzVLwMAqOEuqY4n7dKli6xater/XuSSankZAEANVi3JoIGTkJBQHU8NAAgR1XIOaNeuXZKUlCRt27aVu+++W/bt21fhsgUFBZKbm+s3AQBCX5UHUJ8+fSQ9PV1WrFgh8+fPlz179sh1110nJ0+eLHf5tLQ0iYmJKZ5atmxZ1asEAAhCEY7jONX5AidOnJDWrVvLiy++KKNHjy63BqSTj9aACCEAqPlycnIkOjq6wservXdAbGysdOzYUTIzM8t9PCoqykwAgPBS7b8DOnXqlOzevVsSExOr+6UAAOEcQNOmTZN169bJ3r175YsvvpDbb79dateuLXfeeWdVvxQAoAar8ia4/fv3m7A5evSoNGnSRK699lrZuHGj+T8AAAHrhOCWdkLQ3nAAgNDuhMBYcAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgRbVfkA4AKqKXanGrqKjIdZlAjrns5QKbBSWuCn2h2rdvL15UdHFQG6gBAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwApGwwYuUkREREDKeBkFunnz5q7LqJSUFNdlPvnkE9dlTp8+LaHGy8jWXgwfPtxTuWeffVaCBTUgAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCwUgBC7wMLOrFdddd56lcnz59XJdJSkpyXeaVV16RUNO0aVPXZVJTU12Xyc3NlZqOGhAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWMFgpMBFql27tusyZ8+edV3mqquucl3msssuEy8OHTrkukyHDh1cl1myZInrMseOHXNdpl69euLFt99+67pMfHy86zLR0dGuy+zfv19qOmpAAAArCCAAQM0IoPXr18uQIUPMtT8iIiJk6dKlfo87jiMzZ86UxMREU+0dOHCg7Nq1qyrXGQAQjgF0+vRp6dGjh8ybN6/cx5977jlzkanXX39dvvzyS2nQoIG52FJ+fn5VrC8AIFw7IQwePNhM5dHaz9y5c+Wxxx6T2267zcx7++23pVmzZqamNGLEiItfYwBASKjSc0B79uyR7Oxs0+zmExMTYy7vu2HDhnLLFBQUmEvLlpwAAKGvSgNIw0dpjackve97rLS0tDQTUr6pZcuWVblKAIAgZb0X3IwZMyQnJ6d4ysrKsr1KAICaFkAJCQnl/ohN7/seKy0qKsr8CKvkBAAIfVUaQMnJySZoMjIyiufpOR3tDZeSklKVLwUACLdecKdOnZLMzEy/jgdbt26VuLg4adWqlUyePFmeeuopMyyHBtLjjz9ufjM0dOjQql53AEA4BdCmTZvkhhtuKL4/depUczty5EhJT0+X6dOnm98KjR07Vk6cOCHXXnutrFixQurWrVu1aw4AqNEiHP3xThDRJjvtDQfYUKuW+1bpoqIi12X0B9pu6QgjbunPHLzw8p7atGnjukxsbKzrMsePH3ddxusXYC+fk5eOVLU87HdeP1ttpQoU7Vh2vvP61nvBAQDCEwEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAADXjcgwIbhEREa7LeB0Q3csIvl5ey0uZ2rVrixfnzp2TQBg3bpzrMtnZ2a7L5OfnixdeRrb2MuJ06asnV9dn62V0b6WXlnGrsLDQdZloD1eC1qtJB2qEby/b4UJQAwIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKxiMNMQGCfU6sKgXXgd4DMTgk4EaVFTdeeedrsskJCS4LrNlyxbXZSIjI8WL2NhY12WOHj3qusyxY8dcl2ncuLHrMo0aNRIvvA5qG4iBfevXr+/ptTp06OC6zNatW6U6UAMCAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsYjDRAAjVIqJdBDb2U8Trgp5ftEMiBRe+55x7XZTp16uS6TFZWVkAG4fQyCK6qV6+e6zLfffddQAYJ9TIIbl5ennhRt27doB142KvU1FTXZRiMFAAQUgggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgRVgPRup1EE4vvAw26GVQQy8DNXopE0hJSUmuywwbNixgg3Du2rXLdZmGDRu6LhMVFeW6THx8vHhRWFgYkH28fv36EgheB7QtKCgIyGudPn06YH+3ffv2lWBBDQgAYAUBBACoGQG0fv16GTJkiGkW0SaipUuX+j0+atQoM7/kdPPNN1flOgMAwjGAtK2yR48eMm/evAqX0cA5ePBg8bRo0aKLXU8AQLh3Qhg8eLCZKjtZmpCQcDHrBQAIcdVyDmjt2rXStGlTc6ni8ePHy9GjR8/byyQ3N9dvAgCEvioPIG1+e/vttyUjI0OeffZZWbdunakxVdQ1MS0tTWJiYoqnli1bVvUqAQDC4XdAI0aMKP5/t27dpHv37tKuXTtTKxowYECZ5WfMmCFTp04tvq81IEIIAEJftXfDbtu2rTRu3FgyMzMrPF8UHR3tNwEAQl+1B9D+/fvNOaDExMTqfikAQCg3wZ06dcqvNrNnzx7ZunWrxMXFmWnOnDkyfPhw0wtu9+7dMn36dGnfvr2kpqZW9boDAMIpgDZt2iQ33HBD8X3f+ZuRI0fK/PnzZdu2bfLWW2/JiRMnzI9VBw0aJE8++aSncawAAKErwvEygmA10k4I2htOBwp1Mxin18EGIdKkSRNP5Vq3bu26TOfOnV2X8dJ862UwTZWfnx+QgUW9nOuMjIwMyOCqqkGDBgEp4+U96Zdbt7weH2rXrh2QgUXPnDkTkP1O6fHVraefftr19t6xY4fk5OScd19nLDgAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgCExiW5q0pRUVG1v0azZs0CNgp0oEYX9jL6cXJysnhRv379gIz6q9egcktHUw/USMFetvnZs2cDsr3z8vLEi4KCAtdl6tSp47rMwYMHA/IZedl26vjx4wEZpfrSSy8NyKjbSq/V5lZ8fHy17N/UgAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADAiqAdjNStgQMHui6TlJTk6bW8DKjZtGnTgAyo6WUQVy/vR508eTIgAzV6GTwxIiJCvIiKigrIgJVePlsv26527drihZeBLr3sDzk5OQH5WwokL/tDkYe/Wy+D4HodNNbt4LkMRgoACGoEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsCJoByO98cYb5ZJLLnz1Ro8e7fo1duzYIV4cPHjQdZnc3NyADCRZWFgYkNfxysuAlV4GTzx37px4ER0dHZCBT70MJOllwMrIyEjxwssAsM2aNXNdpkuXLgF5T4Hcx70M5Fq/fn3XZfLz8yVQ63f48OFq2VepAQEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFUE7GOnmzZtdDfJ49dVXu36Nbt26iRd9+/aVQDh79mxABvs8duyY6zJey+Xk5ARkMFIvA4Sq+Ph412U6deoUkMEnvQyU6jiOeNGjRw/XZbZt2+a6zN69e12XGThwoOsyUVFR4oXX7ReIv/XvvvvO02t5GRi5YcOG1TIYMDUgAIAVBBAAIPgDKC0tTXr16iWNGjWSpk2bytChQ2Xnzp1lrlExYcIE05Sh1bbhw4fLoUOHqnq9AQDhFEDr1q0z4bJx40ZZuXKlnDlzRgYNGuR3gaMpU6bIxx9/LIsXLzbLHzhwQIYNG1Yd6w4ACJdOCCtWrPC7n56ebmpC2mGgX79+5gTzm2++Ke+++665oqlasGCBXHbZZSa0vHQUAACEpos6B+Tr0RQXF2duNYi0VlSyl0rnzp2lVatWsmHDhnKfo6CgwPTKKDkBAEKf5wDSa35PnjzZdEnu2rWrmZednW26zMbGxpa5Vrw+VtF5pZiYmOKpZcuWXlcJABAOAaTngrZv3y7vvffeRa3AjBkzTE3KN2VlZV3U8wEAQviHqBMnTpTly5fL+vXrpUWLFsXzExISpLCwUE6cOOFXC9JecPpYRT8Q8/ojMQBAmNSA9FfBGj5LliyR1atXS3Jyst/jPXv2lMjISMnIyCiep9209+3bJykpKVW31gCA8KoBabOb9nBbtmyZ+S2Q77yOnrupV6+euR09erRMnTrVdEzQoUMmTZpkwocecAAAzwE0f/58c9u/f3+/+drVetSoUeb/L730ktSqVcv8AFV7uKWmpsrvf/97Ny8DAAgDEU6gRtu7QNoNW2tSwcztwHyqT58+rst07NjRdZlrrrnGdRn9LZcXXgbHbNCgQUAGFvW6W2vvzkAMyrpjxw7XZfTH32598skn4oWOaBKsPvroI9dl9KcgXhw5ciQgAwKf9FDGywCmSisGbk2bNs31319eXp7pWHa+4wRjwQEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKRsMGAFQLRsMGAAQlAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQACD4AygtLU169eoljRo1kqZNm8rQoUNl586dfsv0799fIiIi/KZx48ZV9XoDAMIpgNatWycTJkyQjRs3ysqVK+XMmTMyaNAgOX36tN9yY8aMkYMHDxZPzz33XFWvNwCghrvEzcIrVqzwu5+enm5qQps3b5Z+/foVz69fv74kJCRU3VoCAELORZ0DysnJMbdxcXF+8xcuXCiNGzeWrl27yowZMyQvL6/C5ygoKJDc3Fy/CQAQBhyPzp0759x6661O3759/ea/8cYbzooVK5xt27Y577zzjtO8eXPn9ttvr/B5Zs2a5ehqMDExMTFJSE05OTnnzRHPATRu3DindevWTlZW1nmXy8jIMCuSmZlZ7uP5+flmJX2TPp/tjcbExMTEJNUeQK7OAflMnDhRli9fLuvXr5cWLVqcd9k+ffqY28zMTGnXrl2Zx6OioswEAAgvrgJIa0yTJk2SJUuWyNq1ayU5ObnSMlu3bjW3iYmJ3tcSABDeAaRdsN99911ZtmyZ+S1Qdna2mR8TEyP16tWT3bt3m8dvueUWiY+Pl23btsmUKVNMD7nu3btX13sAANREbs77VNTOt2DBAvP4vn37nH79+jlxcXFOVFSU0759e+ehhx6qtB2wJF3WdrslExMTE5Nc9FTZsT/i/wdL0NBu2FqjAgDUbPpTnejo6AofZyw4AIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVQRdAjuPYXgUAQACO50EXQCdPnrS9CgCAABzPI5wgq3IUFRXJgQMHpFGjRhIREeH3WG5urrRs2VKysrIkOjpawhXb4Udshx+xHX7Edgie7aCxouGTlJQktWpVXM+5RIKMrmyLFi3Ou4xu1HDewXzYDj9iO/yI7fAjtkNwbIeYmJhKlwm6JjgAQHgggAAAVtSoAIqKipJZs2aZ23DGdvgR2+FHbIcfsR1q3nYIuk4IAIDwUKNqQACA0EEAAQCsIIAAAFYQQAAAKwggAIAVNSaA5s2bJ23atJG6detKnz595KuvvrK9SgE3e/ZsMzxRyalz584S6tavXy9Dhgwxw3roe166dKnf49qRc+bMmZKYmCj16tWTgQMHyq5duyTctsOoUaPK7B8333yzhJK0tDTp1auXGaqradOmMnToUNm5c6ffMvn5+TJhwgSJj4+Xhg0byvDhw+XQoUMSbtuhf//+ZfaHcePGSTCpEQH0/vvvy9SpU03f9i1btkiPHj0kNTVVDh8+LOGmS5cucvDgweLps88+k1B3+vRp85nrl5DyPPfcc/LKK6/I66+/Ll9++aU0aNDA7B96IAqn7aA0cEruH4sWLZJQsm7dOhMuGzdulJUrV8qZM2dk0KBBZtv4TJkyRT7++GNZvHixWV7Hlhw2bJiE23ZQY8aM8dsf9G8lqDg1QO/evZ0JEyYU3z937pyTlJTkpKWlOeFk1qxZTo8ePZxwprvskiVLiu8XFRU5CQkJzvPPP18878SJE05UVJSzaNEiJ1y2gxo5cqRz2223OeHk8OHDZlusW7eu+LOPjIx0Fi9eXLzMN998Y5bZsGGDEy7bQV1//fXOAw884ASzoK8BFRYWyubNm02zSskBS/X+hg0bJNxo05I2wbRt21buvvtu2bdvn4SzPXv2SHZ2tt/+oYMgajNtOO4fa9euNU0ynTp1kvHjx8vRo0cllOXk5JjbuLg4c6vHCq0NlNwftJm6VatWIb0/5JTaDj4LFy6Uxo0bS9euXWXGjBmSl5cnwSToRsMu7ciRI3Lu3Dlp1qyZ33y9v2PHDgknelBNT083BxetTs+ZM0euu+462b59u2kLDkcaPqq8/cP3WLjQ5jdtakpOTpbdu3fLo48+KoMHDzYH3tq1a0uo0Uu3TJ48Wfr27WsOsEo/8zp16khsbGzY7A9F5WwHddddd0nr1q3NF9Zt27bJww8/bM4TffjhhxIsgj6A8H/0YOLTvXt3E0i6g33wwQcyevRoq+sG+0aMGFH8/27dupl9pF27dqZWNGDAAAk1eg5Ev3yFw3lQL9th7NixfvuDdtLR/UC/nOh+EQyCvglOq4/67a10Lxa9n5CQIOFMv+V17NhRMjMzJVz59gH2j7K0mVb/fkJx/5g4caIsX75c1qxZ43f9MP3Mtdn+xIkTYbE/TKxgO5RHv7CqYNofgj6AtDrds2dPycjI8Kty6v2UlBQJZ6dOnTLfZvSbTbjS5iY9sJTcP/SKkNobLtz3j/3795tzQKG0f2j/Cz3oLlmyRFavXm0+/5L0WBEZGem3P2izk54rDaX9walkO5Rn69at5jao9genBnjvvfdMr6b09HTnP//5jzN27FgnNjbWyc7OdsLJgw8+6Kxdu9bZs2eP8/nnnzsDBw50GjdubHrAhLKTJ086X3/9tZl0l33xxRfN/7/99lvz+DPPPGP2h2XLljnbtm0zPcGSk5OdH374wQmX7aCPTZs2zfT00v1j1apVzpVXXul06NDByc/Pd0LF+PHjnZiYGPN3cPDgweIpLy+veJlx48Y5rVq1clavXu1s2rTJSUlJMVMoGV/JdsjMzHSeeOIJ8/51f9C/jbZt2zr9+vVzgkmNCCD16quvmp2qTp06plv2xo0bnXBzxx13OImJiWYbNG/e3NzXHS3UrVmzxhxwS0/a7djXFfvxxx93mjVrZr6oDBgwwNm5c6cTTttBDzyDBg1ymjRpYroht27d2hkzZkzIfUkr7/3rtGDBguJl9IvHfffd51x66aVO/fr1ndtvv90cnMNpO+zbt8+ETVxcnPmbaN++vfPQQw85OTk5TjDhekAAACuC/hwQACA0EUAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACA2PD/AB1sE4m6vaa/AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicted 9, and the actual label is 9.\n"
     ]
    }
   ],
   "source": [
    "# Test model on single image\n",
    "\n",
    "image, label = test_dataset[0]\n",
    "predicted_label = predict_single_image(image, label, model)\n",
    "\n",
    "print(f\"The model predicted {predicted_label}, and the actual label is {label}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
